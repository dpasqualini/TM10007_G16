{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "source": [
    "# TM10007 Assignment template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "CiDn2Sk-VWqE",
    "outputId": "64224cd2-6054-4b04-a3f6-af8290400dfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Run this to use from colab environment\n",
    "%pip install -q --upgrade git+https://github.com/jveenland/tm10007_ml.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and cleaning\n",
    "\n",
    "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NE_fTbKGe5z"
   },
   "outputs": [],
   "source": [
    "# Data loading functions. Uncomment the one you want to use\n",
    "from worcliver.load_data import load_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data clean-up (before splitting data)\n",
    "In this section double entries, such as repeated features and samples, will be removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples (after removal of duplicates): 186, the number of duplicates that had to be removed: 0\n",
      "The number of columns (after removal of duplicates): 494, the number of duplicates that had to be removed: 0\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "'''\n",
    "These 2 lines add a duplicate sample in the DataFrame, you can than observe what the effect is \n",
    "in the printed sentence. If you'd like to see it indeed works, please uncomment these lines.\n",
    "'''\n",
    "# row = df.iloc[0].copy()\n",
    "# df = df.append(row, ignore_index=True)\n",
    "'''\n",
    "In the lines below we first drop all duplicate entries, whether it is a duplicate row or a column. \n",
    "Additionally, the number of duplicates will be returned to the user.\n",
    "'''\n",
    "\n",
    "df_f = df.drop_duplicates()\n",
    "print(f'The number of samples (after removal of duplicates): {len(df_f.index)}, the number of duplicates that had to be removed: {len(df.index)-len(df_f.index)}')\n",
    "print(f'The number of columns (after removal of duplicates): {len(df_f.columns)}, the number of duplicates that had to be removed: {len(df.columns)-len(df_f.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_f                                       # So we can just use df from now on\n",
    "df = df.replace('', np.nan)                     # Any empty values are replaced for NaN\n",
    "# df.describe(include='all')                    # Uncomment if interested"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The table above shows there are only 2 labels present in the dataset, from observation of the csv.file we can see the labels are 'malignant' and 'benigne'. What is also stated here, that 94 of the 186 samples was labeled malignant (and thus 92 samples are labeled benigne.) This information is usefull in the next step, to determine whether a stratified splitting of our data, would be necessary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data splitting (1/2)\n",
    "In this section the dataset will be split into two datasets, the Design set (D_set) and the Final Test set (Ft_set). This splitting will be performed randomly where 80% will end up in D_set and the remaining 20% will be stored in Ft_set. Ft_set will not be used at all, until the very latest to evaluate our tool and establish how generalising the tool is. In the initial split we will randomly split the dataset, as both labels are equally abundant in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>PREDICT_original_sf_compactness_avg_2.5D</th>\n",
       "      <th>PREDICT_original_sf_compactness_std_2.5D</th>\n",
       "      <th>PREDICT_original_sf_rad_dist_avg_2.5D</th>\n",
       "      <th>PREDICT_original_sf_rad_dist_std_2.5D</th>\n",
       "      <th>PREDICT_original_sf_roughness_avg_2.5D</th>\n",
       "      <th>PREDICT_original_sf_roughness_std_2.5D</th>\n",
       "      <th>PREDICT_original_sf_convexity_avg_2.5D</th>\n",
       "      <th>PREDICT_original_sf_convexity_std_2.5D</th>\n",
       "      <th>PREDICT_original_sf_cvar_avg_2.5D</th>\n",
       "      <th>...</th>\n",
       "      <th>PREDICT_original_phasef_phasesym_median_WL3_N5</th>\n",
       "      <th>PREDICT_original_phasef_phasesym_std_WL3_N5</th>\n",
       "      <th>PREDICT_original_phasef_phasesym_skewness_WL3_N5</th>\n",
       "      <th>PREDICT_original_phasef_phasesym_kurtosis_WL3_N5</th>\n",
       "      <th>PREDICT_original_phasef_phasesym_peak_WL3_N5</th>\n",
       "      <th>PREDICT_original_phasef_phasesym_peak_position_WL3_N5</th>\n",
       "      <th>PREDICT_original_phasef_phasesym_range_WL3_N5</th>\n",
       "      <th>PREDICT_original_phasef_phasesym_energy_WL3_N5</th>\n",
       "      <th>PREDICT_original_phasef_phasesym_quartile_range_WL3_N5</th>\n",
       "      <th>PREDICT_original_phasef_phasesym_entropy_WL3_N5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>148</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>benign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.810449</td>\n",
       "      <td>0.070357</td>\n",
       "      <td>31.025697</td>\n",
       "      <td>4.674168</td>\n",
       "      <td>8.464892</td>\n",
       "      <td>3.333409</td>\n",
       "      <td>0.958083</td>\n",
       "      <td>0.032232</td>\n",
       "      <td>0.026522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>0.118063</td>\n",
       "      <td>2.670400</td>\n",
       "      <td>10.224843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.436461</td>\n",
       "      <td>845.910424</td>\n",
       "      <td>0.080586</td>\n",
       "      <td>12.147511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.071607</td>\n",
       "      <td>0.048925</td>\n",
       "      <td>14.232578</td>\n",
       "      <td>2.753151</td>\n",
       "      <td>3.356987</td>\n",
       "      <td>2.270701</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>0.032174</td>\n",
       "      <td>0.014970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019361</td>\n",
       "      <td>0.036251</td>\n",
       "      <td>1.599388</td>\n",
       "      <td>19.939644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111047</td>\n",
       "      <td>1283.408789</td>\n",
       "      <td>0.091892</td>\n",
       "      <td>1.962374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.549046</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>9.648695</td>\n",
       "      <td>1.130516</td>\n",
       "      <td>2.310309</td>\n",
       "      <td>0.265697</td>\n",
       "      <td>0.790738</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.007132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022161</td>\n",
       "      <td>0.517983</td>\n",
       "      <td>-0.850033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017016</td>\n",
       "      <td>4.299305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.264275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774140</td>\n",
       "      <td>0.040098</td>\n",
       "      <td>20.157877</td>\n",
       "      <td>2.747720</td>\n",
       "      <td>6.380224</td>\n",
       "      <td>1.899252</td>\n",
       "      <td>0.951675</td>\n",
       "      <td>0.015465</td>\n",
       "      <td>0.015216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095353</td>\n",
       "      <td>1.696290</td>\n",
       "      <td>2.123002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384490</td>\n",
       "      <td>137.177619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.744170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825621</td>\n",
       "      <td>0.054622</td>\n",
       "      <td>27.523779</td>\n",
       "      <td>3.986081</td>\n",
       "      <td>7.914242</td>\n",
       "      <td>2.838249</td>\n",
       "      <td>0.963365</td>\n",
       "      <td>0.022517</td>\n",
       "      <td>0.023106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116595</td>\n",
       "      <td>2.446979</td>\n",
       "      <td>5.836302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453225</td>\n",
       "      <td>323.948124</td>\n",
       "      <td>0.043008</td>\n",
       "      <td>12.154106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.860922</td>\n",
       "      <td>0.080052</td>\n",
       "      <td>38.818462</td>\n",
       "      <td>6.072275</td>\n",
       "      <td>10.175131</td>\n",
       "      <td>4.034999</td>\n",
       "      <td>0.976377</td>\n",
       "      <td>0.034812</td>\n",
       "      <td>0.032951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139734</td>\n",
       "      <td>3.043456</td>\n",
       "      <td>9.470647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503929</td>\n",
       "      <td>987.265922</td>\n",
       "      <td>0.150151</td>\n",
       "      <td>13.631222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926346</td>\n",
       "      <td>0.245769</td>\n",
       "      <td>73.610032</td>\n",
       "      <td>16.559442</td>\n",
       "      <td>21.955618</td>\n",
       "      <td>15.637597</td>\n",
       "      <td>1.001046</td>\n",
       "      <td>0.199697</td>\n",
       "      <td>0.094500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182629</td>\n",
       "      <td>0.206225</td>\n",
       "      <td>11.394947</td>\n",
       "      <td>152.451063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.647253</td>\n",
       "      <td>7624.462235</td>\n",
       "      <td>0.356156</td>\n",
       "      <td>16.720278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 494 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label  PREDICT_original_sf_compactness_avg_2.5D  \\\n",
       "count      148                                148.000000   \n",
       "unique       2                                       NaN   \n",
       "top     benign                                       NaN   \n",
       "freq        75                                       NaN   \n",
       "mean       NaN                                  0.810449   \n",
       "std        NaN                                  0.071607   \n",
       "min        NaN                                  0.549046   \n",
       "25%        NaN                                  0.774140   \n",
       "50%        NaN                                  0.825621   \n",
       "75%        NaN                                  0.860922   \n",
       "max        NaN                                  0.926346   \n",
       "\n",
       "        PREDICT_original_sf_compactness_std_2.5D  \\\n",
       "count                                 148.000000   \n",
       "unique                                       NaN   \n",
       "top                                          NaN   \n",
       "freq                                         NaN   \n",
       "mean                                    0.070357   \n",
       "std                                     0.048925   \n",
       "min                                     0.004729   \n",
       "25%                                     0.040098   \n",
       "50%                                     0.054622   \n",
       "75%                                     0.080052   \n",
       "max                                     0.245769   \n",
       "\n",
       "        PREDICT_original_sf_rad_dist_avg_2.5D  \\\n",
       "count                              148.000000   \n",
       "unique                                    NaN   \n",
       "top                                       NaN   \n",
       "freq                                      NaN   \n",
       "mean                                31.025697   \n",
       "std                                 14.232578   \n",
       "min                                  9.648695   \n",
       "25%                                 20.157877   \n",
       "50%                                 27.523779   \n",
       "75%                                 38.818462   \n",
       "max                                 73.610032   \n",
       "\n",
       "        PREDICT_original_sf_rad_dist_std_2.5D  \\\n",
       "count                              148.000000   \n",
       "unique                                    NaN   \n",
       "top                                       NaN   \n",
       "freq                                      NaN   \n",
       "mean                                 4.674168   \n",
       "std                                  2.753151   \n",
       "min                                  1.130516   \n",
       "25%                                  2.747720   \n",
       "50%                                  3.986081   \n",
       "75%                                  6.072275   \n",
       "max                                 16.559442   \n",
       "\n",
       "        PREDICT_original_sf_roughness_avg_2.5D  \\\n",
       "count                               148.000000   \n",
       "unique                                     NaN   \n",
       "top                                        NaN   \n",
       "freq                                       NaN   \n",
       "mean                                  8.464892   \n",
       "std                                   3.356987   \n",
       "min                                   2.310309   \n",
       "25%                                   6.380224   \n",
       "50%                                   7.914242   \n",
       "75%                                  10.175131   \n",
       "max                                  21.955618   \n",
       "\n",
       "        PREDICT_original_sf_roughness_std_2.5D  \\\n",
       "count                               148.000000   \n",
       "unique                                     NaN   \n",
       "top                                        NaN   \n",
       "freq                                       NaN   \n",
       "mean                                  3.333409   \n",
       "std                                   2.270701   \n",
       "min                                   0.265697   \n",
       "25%                                   1.899252   \n",
       "50%                                   2.838249   \n",
       "75%                                   4.034999   \n",
       "max                                  15.637597   \n",
       "\n",
       "        PREDICT_original_sf_convexity_avg_2.5D  \\\n",
       "count                               148.000000   \n",
       "unique                                     NaN   \n",
       "top                                        NaN   \n",
       "freq                                       NaN   \n",
       "mean                                  0.958083   \n",
       "std                                   0.030172   \n",
       "min                                   0.790738   \n",
       "25%                                   0.951675   \n",
       "50%                                   0.963365   \n",
       "75%                                   0.976377   \n",
       "max                                   1.001046   \n",
       "\n",
       "        PREDICT_original_sf_convexity_std_2.5D  \\\n",
       "count                               148.000000   \n",
       "unique                                     NaN   \n",
       "top                                        NaN   \n",
       "freq                                       NaN   \n",
       "mean                                  0.032232   \n",
       "std                                   0.032174   \n",
       "min                                   0.003572   \n",
       "25%                                   0.015465   \n",
       "50%                                   0.022517   \n",
       "75%                                   0.034812   \n",
       "max                                   0.199697   \n",
       "\n",
       "        PREDICT_original_sf_cvar_avg_2.5D  ...  \\\n",
       "count                          148.000000  ...   \n",
       "unique                                NaN  ...   \n",
       "top                                   NaN  ...   \n",
       "freq                                  NaN  ...   \n",
       "mean                             0.026522  ...   \n",
       "std                              0.014970  ...   \n",
       "min                              0.007132  ...   \n",
       "25%                              0.015216  ...   \n",
       "50%                              0.023106  ...   \n",
       "75%                              0.032951  ...   \n",
       "max                              0.094500  ...   \n",
       "\n",
       "        PREDICT_original_phasef_phasesym_median_WL3_N5  \\\n",
       "count                                       148.000000   \n",
       "unique                                             NaN   \n",
       "top                                                NaN   \n",
       "freq                                               NaN   \n",
       "mean                                          0.004139   \n",
       "std                                           0.019361   \n",
       "min                                           0.000000   \n",
       "25%                                           0.000000   \n",
       "50%                                           0.000000   \n",
       "75%                                           0.000000   \n",
       "max                                           0.182629   \n",
       "\n",
       "        PREDICT_original_phasef_phasesym_std_WL3_N5  \\\n",
       "count                                    148.000000   \n",
       "unique                                          NaN   \n",
       "top                                             NaN   \n",
       "freq                                            NaN   \n",
       "mean                                       0.118063   \n",
       "std                                        0.036251   \n",
       "min                                        0.022161   \n",
       "25%                                        0.095353   \n",
       "50%                                        0.116595   \n",
       "75%                                        0.139734   \n",
       "max                                        0.206225   \n",
       "\n",
       "        PREDICT_original_phasef_phasesym_skewness_WL3_N5  \\\n",
       "count                                         148.000000   \n",
       "unique                                               NaN   \n",
       "top                                                  NaN   \n",
       "freq                                                 NaN   \n",
       "mean                                            2.670400   \n",
       "std                                             1.599388   \n",
       "min                                             0.517983   \n",
       "25%                                             1.696290   \n",
       "50%                                             2.446979   \n",
       "75%                                             3.043456   \n",
       "max                                            11.394947   \n",
       "\n",
       "        PREDICT_original_phasef_phasesym_kurtosis_WL3_N5  \\\n",
       "count                                         148.000000   \n",
       "unique                                               NaN   \n",
       "top                                                  NaN   \n",
       "freq                                                 NaN   \n",
       "mean                                           10.224843   \n",
       "std                                            19.939644   \n",
       "min                                            -0.850033   \n",
       "25%                                             2.123002   \n",
       "50%                                             5.836302   \n",
       "75%                                             9.470647   \n",
       "max                                           152.451063   \n",
       "\n",
       "        PREDICT_original_phasef_phasesym_peak_WL3_N5  \\\n",
       "count                                          148.0   \n",
       "unique                                           NaN   \n",
       "top                                              NaN   \n",
       "freq                                             NaN   \n",
       "mean                                             0.0   \n",
       "std                                              0.0   \n",
       "min                                              0.0   \n",
       "25%                                              0.0   \n",
       "50%                                              0.0   \n",
       "75%                                              0.0   \n",
       "max                                              0.0   \n",
       "\n",
       "        PREDICT_original_phasef_phasesym_peak_position_WL3_N5  \\\n",
       "count                                               148.0       \n",
       "unique                                                NaN       \n",
       "top                                                   NaN       \n",
       "freq                                                  NaN       \n",
       "mean                                                  0.0       \n",
       "std                                                   0.0       \n",
       "min                                                   0.0       \n",
       "25%                                                   0.0       \n",
       "50%                                                   0.0       \n",
       "75%                                                   0.0       \n",
       "max                                                   0.0       \n",
       "\n",
       "        PREDICT_original_phasef_phasesym_range_WL3_N5  \\\n",
       "count                                      148.000000   \n",
       "unique                                            NaN   \n",
       "top                                               NaN   \n",
       "freq                                              NaN   \n",
       "mean                                         0.436461   \n",
       "std                                          0.111047   \n",
       "min                                          0.017016   \n",
       "25%                                          0.384490   \n",
       "50%                                          0.453225   \n",
       "75%                                          0.503929   \n",
       "max                                          0.647253   \n",
       "\n",
       "        PREDICT_original_phasef_phasesym_energy_WL3_N5  \\\n",
       "count                                       148.000000   \n",
       "unique                                             NaN   \n",
       "top                                                NaN   \n",
       "freq                                               NaN   \n",
       "mean                                        845.910424   \n",
       "std                                        1283.408789   \n",
       "min                                           4.299305   \n",
       "25%                                         137.177619   \n",
       "50%                                         323.948124   \n",
       "75%                                         987.265922   \n",
       "max                                        7624.462235   \n",
       "\n",
       "        PREDICT_original_phasef_phasesym_quartile_range_WL3_N5  \\\n",
       "count                                          148.000000        \n",
       "unique                                                NaN        \n",
       "top                                                   NaN        \n",
       "freq                                                  NaN        \n",
       "mean                                             0.080586        \n",
       "std                                              0.091892        \n",
       "min                                              0.000000        \n",
       "25%                                              0.000000        \n",
       "50%                                              0.043008        \n",
       "75%                                              0.150151        \n",
       "max                                              0.356156        \n",
       "\n",
       "        PREDICT_original_phasef_phasesym_entropy_WL3_N5  \n",
       "count                                        148.000000  \n",
       "unique                                              NaN  \n",
       "top                                                 NaN  \n",
       "freq                                                NaN  \n",
       "mean                                          12.147511  \n",
       "std                                            1.962374  \n",
       "min                                            6.264275  \n",
       "25%                                           10.744170  \n",
       "50%                                           12.154106  \n",
       "75%                                           13.631222  \n",
       "max                                           16.720278  \n",
       "\n",
       "[11 rows x 494 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# D_set, Ft_set = train_test_split(df, test_size=0.2)\n",
    "# D_set = pd.DataFrame(D_set)\n",
    "# Ft_set = pd.DataFrame(Ft_set)\n",
    "\n",
    "# D_set.describe(include='all')                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D_set.to_csv(\"C:/Users/dgjpa/D_set.csv\")\n",
    "# Ft_set = Ft_set.to_csv(\"C:/Users/dgjpa/Ft_set.csv\")\n",
    "\n",
    "'''\n",
    "These lines were used to save the splitted sets, to make sure Design and Test set won't alter.\n",
    "''' "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data splitting (2/2)\n",
    "In this section D_set will be split into two datasets, the train set (Tr_set) and the Validation set (Va_set). This splitting will be performed randomly where 90% will end up in Tr_set and the remaining 10% will be stored in Va_set. This second splitting will be repeated 10 times with each iteration a different 10% of the samples will be put into the Va_set, as we will use cross-validation to make most out of the data available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_D_set' from 'worcliver.load_data' (c:\\Users\\dgjpa\\OneDrive - Delft University of Technology\\Universiteit\\TM jaar 1\\TM10007\\TM10007_G16\\worcliver\\load_data.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dgjpa\\OneDrive - Delft University of Technology\\Universiteit\\TM jaar 1\\TM10007\\TM10007_G16\\assignment.ipynb Cell 13\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dgjpa/OneDrive%20-%20Delft%20University%20of%20Technology/Universiteit/TM%20jaar%201/TM10007/TM10007_G16/assignment.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mworcliver\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mload_data\u001b[39;00m \u001b[39mimport\u001b[39;00m load_D_set\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dgjpa/OneDrive%20-%20Delft%20University%20of%20Technology/Universiteit/TM%20jaar%201/TM10007/TM10007_G16/assignment.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m D_usable \u001b[39m=\u001b[39m load_D_set()\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'load_D_set' from 'worcliver.load_data' (c:\\Users\\dgjpa\\OneDrive - Delft University of Technology\\Universiteit\\TM jaar 1\\TM10007\\TM10007_G16\\worcliver\\load_data.py)"
     ]
    }
   ],
   "source": [
    "from worcliver.load_data import load_D_set\n",
    "\n",
    "D_usable = load_D_set()\n",
    "\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# kf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "# for train_index, test_index in kf.split(data, data['target']):\n",
    "#     X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "#     y_train, y_test = data['target'][train_index], data['target'][test_index]\n",
    "    \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
